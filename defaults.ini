
[DEFAULTS]

#name of the run
name = dance_acapella_unc

# training data directory
training_dir = "/storage/user/steiger/dataset/acapella"

# the batch size
batch_size = 12 

# number of GPUs to use for training
num_gpus = 1 

# number of nodes to use for training
num_nodes = 1 

# number of CPU workers for the DataLoader
num_workers = 4

# Number of audio samples for the training input
sample_size = 65536 

# Number of steps between demos
demo_every = 2000

# Number of denoising steps for the demos       
demo_steps = 250

# Number of demos to create
num_demos = 16

# the EMA decay
ema_decay = 0.995       

# the random seed
seed = 42

# Batches for gradient accumulation
accum_batches = 2

# The sample rate of the audio
sample_rate = 44100

# Number of steps between checkpoints
checkpoint_every = 10000                              

# unused, required by the model code
latent_dim = 0              

# If true training data is kept in RAM
cache_training_data = False  

# randomly crop input audio? (for augmentation)
random_crop = True 

# checkpoint file to (re)start training from
ckpt_path = ''

# Path to output the model checkpoints
save_path = ''

#the multiprocessing start method ['fork', 'forkserver', 'spawn']
start_method = 'spawn'
